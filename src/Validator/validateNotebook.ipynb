{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of hot spots found: 0.717741935483871\n",
      "There were 0 false positives.\n",
      "There was a classification accuracy of 100.0 percent.\n",
      "There was an average hot spot distance of 0.0\n",
      "There was an average registration distance of 0.0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math \n",
    "\n",
    "'''\n",
    "to dos: \n",
    "filter out anomalies in the csv we populate (results)\n",
    "figure out why hotspotDistances doesn't have the complete length of 124; the Percent of hotspots found should be 100% since the two files have the same content right now\n",
    "\n",
    "'''\n",
    "\n",
    "# metrics:\n",
    "falsePositives = 0\n",
    "hotSpotDistances = []\n",
    "registrationDistances = []\n",
    "classificationTrue = 0\n",
    "classificationFalse = 0\n",
    "expectedTruePositives = 0\n",
    "actualTruePositives = 0\n",
    "# f1 = file('outputExample.csv', 'r')\n",
    "with open('validationWithoutAnomalies.csv', 'r') as answers:\n",
    "    ans = csv.reader(answers)\n",
    "\n",
    "# col 5 and 6 = hotspot\n",
    "# col 7-10 = registration\n",
    "# col 12 = species_id \n",
    "# assuming that are not taking in hotspot_type (bc no anomalies)\n",
    "# mydict = {rows[0]: [rows[5], rows[6], rows[7], rows[8], rows[9], rows[10], rows[12]] for rows in c1}\n",
    "    masterlist = list(ans)\n",
    "    # dictionary with photoIds (thermal image names) and pointers to the rows with that image\n",
    "    mydict = {}\n",
    "\n",
    "    for i in range(len(masterlist)): \n",
    "        # assume thermal phone name is id and is in 3rd (index 2) column\n",
    "        photoID = masterlist[i][2]\n",
    "        expectedTruePositives = len(masterlist)\n",
    "        rows = mydict.get(photoID, [])\n",
    "        if (rows == []):\n",
    "            mydict[photoID] = [i];\n",
    "        else:\n",
    "            if rows:\n",
    "                mydict[photoID] = rows.append(i)\n",
    "    with open('validationWithoutAnomalies.csv', 'r') as results:\n",
    "        res = csv.reader(results)\n",
    "        resList = list(res)\n",
    "        # todo: filter out anomalies (skip first row of CSV ** asuming there is a title row **)\n",
    "        for j in range(1, len(resList)): \n",
    "            resultRow = resList[j]\n",
    "            photoID2 = resultRow[2]\n",
    "            rows = mydict.get(photoID2, [])\n",
    "            if (rows == []):\n",
    "                falsePositives+=1\n",
    "            else:\n",
    "                if rows:\n",
    "                    for i in rows:\n",
    "                        row = masterlist[i]\n",
    "                        x1 = int(row[5])\n",
    "                        y1 = int(row[6])\n",
    "                        x2 = int(resultRow[5])\n",
    "                        y2 = int(resultRow[6])\n",
    "                        dist = math.hypot(x2 - x1, y2 - y1)\n",
    "                        # decide that detected hotspot if < 10\n",
    "                        if dist < 10:\n",
    "                            # check bounding boxes\n",
    "                            midX1 = (int(row[7]) + int(row[9])) / 2\n",
    "                            midY1 = (int(row[8]) + int(row[10])) / 2\n",
    "                            midX2 = (int(resultRow[7]) + int(resultRow[9])) / 2\n",
    "                            midY2 = (int(resultRow[8]) + int(resultRow[10])) / 2\n",
    "                            dist2 = math.hypot(midX2 - midX1, midY2 - midY1)\n",
    "                            hotSpotDistances.append(dist)\n",
    "                            registrationDistances.append(dist2)\n",
    "                            # classification accuracy\n",
    "                            if (row[12] == resultRow[12]):\n",
    "                                classificationTrue += 1 \n",
    "                            else:\n",
    "                                classificationFalse += 1\n",
    "                        else:\n",
    "                            falsePositives += 1\n",
    "    print(\"Percent of hot spots found: \" + str(len(hotSpotDistances) / expectedTruePositives))\n",
    "    print(\"There were \" + str(falsePositives) + \" false positives.\")\n",
    "    if ((classificationTrue + classificationFalse) > 0):\n",
    "        print(\"There was a classification accuracy of \" + str((classificationTrue / (classificationTrue + classificationFalse)) * 100) + \" percent.\")\n",
    "    if (len(hotSpotDistances) > 0):\n",
    "        print(\"There was an average hot spot distance of \" + str(sum(hotSpotDistances) / len(hotSpotDistances)))\n",
    "    if (len(registrationDistances) > 0):\n",
    "        print(\"There was an average registration distance of \" + str(sum(registrationDistances) / len(registrationDistances)))\n",
    "    \n",
    "        \n",
    "                        \n",
    "                        \n",
    "                \n",
    "            \n",
    "\n",
    "# f1.close()\n",
    "# f3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
