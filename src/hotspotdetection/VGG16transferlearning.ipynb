{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "imgPath = \"/mnt/ml/NOAA/color\"\n",
    "irPath = \"/mnt/ml/NOAA/thermal\"\n",
    "dataPath = \"/mnt/ml/NOAA/arcticseals/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metaparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_crop(img, x1, y1, x2, y2):\n",
    "    return img[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html\n",
    "def SealDataGenerator():\n",
    "    df = pd.read_csv(\"{}/training.csv\".format(dataPath))\n",
    "    rowcount = int(df.shape[0])\n",
    "    train_count = int(rowcount * (1 - VALIDATION_SPLIT))\n",
    "    test_count = rowcount - train_count\n",
    "    x_train = np.zeros([train_count, 512, 512, 3])\n",
    "    x_test = np.zeros([test_count, 512, 512, 3])\n",
    "    y_train = np.zeros([train_count, 1])\n",
    "    y_test = np.zeros([test_count, 1])\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    for index, row in df[:train_count, :]:\n",
    "        imageFile = \"{}/{}\".format(imgPath, row.filt_color)\n",
    "        image = Image.open(imageFile)\n",
    "        \n",
    "        # TODO: Some images have negative bounding boxes.\n",
    "        # print((imageFile, row.thumb_left, row.thumb_top, row.thumb_right, row.thumb_bottom))\n",
    "        if (row.thumb_left < 0 or row.thumb_top < 0 or row.thumb_right < 0 or row.thumb_bottom < 0):\n",
    "            print(\"x\", end=\"\")\n",
    "        else:\n",
    "            subimage = image.crop((row.thumb_left, row.thumb_top, row.thumb_right, row.thumb_bottom))\n",
    "            npsubimage = np.array(subimage)\n",
    "            \n",
    "            print (npsubimage.shape)\n",
    "            x_train[i] = npsubimage\n",
    "            print (train)\n",
    "            print(\".\", end=\"\")\n",
    "            \n",
    "        break;\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "    print(\"Images processed {}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-9c6177b1bc37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSealDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-11dcdb7aa29d>\u001b[0m in \u001b[0;36mSealDataGenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimageFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilt_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2486\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2487\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2489\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "SealDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_t, y_t), (x_test, y_test) = cifar10.load_data()\n",
    "print (x_t.shape)\n",
    "print (y_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 model layout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowLayers(base_model):\n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        print (i, layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 (None, 224, 224, 3)\n",
      "1 block1_conv1 (None, 224, 224, 64)\n",
      "2 block1_conv2 (None, 224, 224, 64)\n",
      "3 block1_pool (None, 112, 112, 64)\n",
      "4 block2_conv1 (None, 112, 112, 128)\n",
      "5 block2_conv2 (None, 112, 112, 128)\n",
      "6 block2_pool (None, 56, 56, 128)\n",
      "7 block3_conv1 (None, 56, 56, 256)\n",
      "8 block3_conv2 (None, 56, 56, 256)\n",
      "9 block3_conv3 (None, 56, 56, 256)\n",
      "10 block3_pool (None, 28, 28, 256)\n",
      "11 block4_conv1 (None, 28, 28, 512)\n",
      "12 block4_conv2 (None, 28, 28, 512)\n",
      "13 block4_conv3 (None, 28, 28, 512)\n",
      "14 block4_pool (None, 14, 14, 512)\n",
      "15 block5_conv1 (None, 14, 14, 512)\n",
      "16 block5_conv2 (None, 14, 14, 512)\n",
      "17 block5_conv3 (None, 14, 14, 512)\n",
      "18 block5_pool (None, 7, 7, 512)\n",
      "19 flatten (None, 25088)\n",
      "20 fc1 (None, 4096)\n",
      "21 fc2 (None, 4096)\n",
      "22 predictions (None, 1000)\n"
     ]
    }
   ],
   "source": [
    "original_model = VGG16(weights=None, include_top=True)\n",
    "ShowLayers(original_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing top and last 3 layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 (None, 512, 512, 3)\n",
      "1 block1_conv1 (None, 512, 512, 64)\n",
      "2 block1_conv2 (None, 512, 512, 64)\n",
      "3 block1_pool (None, 256, 256, 64)\n",
      "4 block2_conv1 (None, 256, 256, 128)\n",
      "5 block2_conv2 (None, 256, 256, 128)\n",
      "6 block2_pool (None, 128, 128, 128)\n",
      "7 block3_conv1 (None, 128, 128, 256)\n",
      "8 block3_conv2 (None, 128, 128, 256)\n",
      "9 block3_conv3 (None, 128, 128, 256)\n",
      "10 block3_pool (None, 64, 64, 256)\n",
      "11 block4_conv1 (None, 64, 64, 512)\n",
      "12 block4_conv2 (None, 64, 64, 512)\n",
      "13 block4_conv3 (None, 64, 64, 512)\n",
      "14 block4_pool (None, 32, 32, 512)\n",
      "15 block5_conv1 (None, 32, 32, 512)\n",
      "16 block5_conv2 (None, 32, 32, 512)\n",
      "17 block5_conv3 (None, 32, 32, 512)\n",
      "18 block5_pool (None, 16, 16, 512)\n",
      "19 flatten (None, 131072)\n",
      "20 fc1 (None, 4096)\n",
      "21 fc2 (None, 4096)\n",
      "22 predictions (None, 5)\n"
     ]
    }
   ],
   "source": [
    "# Input = 512x512x3\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(512,512,3)) # Will download the 560MB trained model.\n",
    "\n",
    "# Output = ['Anomaly' 'Bearded Seal' 'Ringed Seal' 'Polar Bear' 'UNK Seal']\n",
    "x = base_model.output\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(4096, name='fc1')(x)\n",
    "x = Dense(4096, name='fc2')(x)\n",
    "predictions = Dense(5, activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "ShowLayers(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze VGG layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers: layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
